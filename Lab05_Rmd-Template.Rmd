---
title: "Ecosystem Dynamics and Global Change - Lab 5"
output:
  html_document:
    df_print: paged
---

## Lab 05 - Time Series Ananlysis

This .Rmd-File accompanies the description of the lab. It is meant to give you some guidance of the order of the processing as well as some smaller code examples that will help you going through the code. In some cases, you will have to come up with your own solution. As a first step - as usual - we load the libraries that we will need during the process. Make sure you use the up-to-date versions of the packages

```{r, silent=TRUE}
library(tidyverse)
library(terra)
library(sf)
library(tidyterra)
library(ggthemes)
```

### Exercise I: Getting to know the data

In moodle, you have received a raster stack and the assignment sheet describes the individual layers. Run the code chunk below to load the raster file, afterwards explore the data a bit to understand what the different layers will mean. The second line defines that the EVI of the year 2013 is being plotted.

```{r}
all_data <- rast('data_EDGC_Lab5.tif')

all_data <- all_data %>%
  mutate(across(starts_with("y"), ~ .x / 1e4))

ggplot() +
  geom_spatraster(
    data = all_data %>% select(starts_with("y"))
  ) +
  facet_wrap(~lyr) +
  scale_fill_gradientn(
    colours = c("orange", "white", "darkgreen"),
    limits = c(0, 1),
    name = "EVI",
    na.value = NA
  )

ggplot() +
  geom_spatraster(
    data = all_data, aes(fill = y2013)
  ) +
    scale_fill_gradientn(
    colours = c("orange", "white", "darkgreen"),
    limits = c(0, 1),
    name = "EVI",
    na.value = NA
  ) +
  labs(title = "2013")
```

Use the code chunk below to mask out the frontier areas by converting them into NA values. The instructions for what frontier areas are can be found in the assignment sheet. After that visualize the same band again as you did above.

```{r}
# quick check...
plot(all_data$onset_yr)
plot(all_data$onset_yr == 0)

# throw out anything but no-frontier-ever-pixels
all_data <- mask(
  all_data,
  all_data$onset_yr > 0,
  maskvalues = T
)

# check result
ggplot() +
  geom_spatraster(
    data = all_data, aes(fill = y2013)
  ) +
    scale_fill_gradientn(
    colours = c("orange", "white", "darkgreen"),
    limits = c(0, 1),
    name = "EVI",
    na.value = NA
  ) +
  labs(
    title = "2013",
    subtitle = "Any agricultural frontiers (1986-2019) are\nmasked out, unrelated to the year shown"
  )
```

### Exercise II: Preparing the data and exploring the drought impact

Apply the chunk below to create a new layer in the raster file that represents the average of the years 2006-2012. Execute the script and carefully examine what the individual commands do, including the parts that include the `tidyR`-syntax. Once you are done with this, use the empty code chunk below to create another new layer that represents the difference between the average of the period 2006-2012 and the drought year 2013. Plot the resulting map and examine the output.

#### Calculating the reference period

```{r}
year_evi_ras <- all_data %>% select(starts_with("y"))

time(year_evi_ras) <- names(year_evi_ras) %>%
  substr(2,5) %>% as.integer()

all_data$EVI_ref_2006_2012 <- year_evi_ras %>% 
  subset(
    time(year_evi_ras) %in% 2006:2012
  ) %>% 
  mean() %>% 
  rename(`reference period 2006-2012` = "mean")

# keep your environment clean:
rm(year_evi_ras)
```

```{r}
all_data$drought_severity <- all_data$y2013 - all_data$EVI_ref_2006_2012

names(all_data$drought_severity) <- "EVI difference 2013 to reference period"

ggplot() +
  geom_spatraster(
    data = all_data,
    aes(fill = `drought_severity`)
  ) +
  scale_fill_gradient2(
    low = "red",
    mid = "white",
    high = "darkgreen",
    midpoint = 0,
    name = "EVI difference",
    na.value = NA
  ) +
  labs(title = "Comparison", subtitle = "2013 vs. reference period 2006-2012")
```

#### Examining EVI values

The code chunk below converts the raster file into a tibble (or data.frame). Execute the code below and carefully examine the newly created dataset. After that, continue with the instructions from the assignment sheet.

```{r}
# evi_pts <- as.points(all_data, values = TRUE, na.rm = TRUE, na.all = FALSE)
# evi_df = as.data.frame(evi_pts, geom = "XY")

# I think it's possible without transforming to points first:

chaco_df <- as.data.frame(all_data, xy = T, na.rm = T)

chaco_df_long <- chaco_df %>%
  pivot_longer(
    !c(x, y, onset_yr, dist_frontier, P_anomaly_Chaco_2013, EVI_ref_2006_2012, drought_severity),
    names_to = "Year",
    values_to = "EVI"
  ) %>% 
  mutate(Year = Year %>% substr(2,5) %>% as.integer())
```

**Question I:**

Provide a suitable visualization for the time series of EVI values. Think also about some summary statistics. Describe in a few sentences your graph, and discuss the suitability of the visualization for the data (but also: what problems do you see by manipulating the data in this way?).

```{r}
ggplot(
  chaco_df_long,
  aes(
    Year,
    EVI,
    group = Year
  )
) +
  geom_violin(fill = "grey", col = "grey") +
  geom_boxplot(width = .2, outliers = F) +
  theme_light() +
  stat_summary(aes(group = 1), colour="deepskyblue2", geom="crossbar") +
  labs(caption = "Blue crossbar represents the mean value") +
  scale_y_continuous(breaks = seq(0, 1, .2), minor_breaks = seq(0, 1, .05))


# Some statistics:

chaco_statistics <- inner_join(
  chaco_df_long %>% 
    group_by(Year) %>% 
    summarise(mean = mean(EVI), .groups = "drop"),
  chaco_df_long %>% 
    group_by(Year) %>% 
    summarise(
      quantile(
        EVI,
        probs = c(0, .05, .1, seq(.25, .75, .25), .9, .95, 1)
      ) %>% 
      as_tibble_row(.name_repair = \(x) paste0('q', parse_number(x)))
    ),
  by = "Year"
)

library(ggrepel)
ggplot(
  chaco_statistics %>% 
    pivot_longer(!Year) %>% 
    filter(!name %in% c("q0", "q100")),
  aes(Year, value, groups = name)
) +
  geom_line() +
  geom_point() +
  geom_label_repel(
    data = filter(
      chaco_statistics %>%
        pivot_longer(!Year) %>%
        filter(!name %in% c("q0", "q100")),
      Year == first(Year)),
    aes(label = name),
    direction = "y",
    segment.colour = "darkgrey"
  ) +
  theme_light()
```

The general problem of visualizing 4d data in a 3d or 2d way is that one of the dimensions has to fall short. This is one of the general problems of multispatiomultitemporal data... In this example, I decided to ignore the x and y, resp. the spatial location, by summarizing it. First plot:

-   The blue crossbars show the mean value over the years.

-   The boxplots show the median and quantiles.

-   In the background, the grey violin (density) plots give a sense of the value distribution.

Second plot: Visualization of the statistics, by simply plotting the mean and some percentiles across years.

This quickly gives a general overview, but completely ignores possible spatial disparities, i.e. spatial patterns.

**Question 2:**

Next, we want to see whether the areas (i.e., pixels) of drought severity and the precipitation anomaly correspond to each other. The basis for this analysis will again be the tibble you created in the previous step – yet, for visualization purposes, we want you to make this comparison based on a random sample of 10,000 points (i.e., pixels). Choose an appropriate visualization for this comparison – be creative here: add a trend line or a local regression. Combine the plot with the previous plot (i.e., the EVI time series)

Create a panel plot consisting of the comparison of ‘drought severity’ with the precipitation anomaly. Critically examining all the maps and plots you have created so far and discuss with your fellow classmates: is the drought of 2013 reflected in the EVI data? What can be problematic in using EVI for such an assessment? Could you think of alternative aggregations compared to the 90th percentile of annual EVI values that is being used here? Provide 2-3 sentences on your examinations; answer them inside the provided space in the .Rmd-File.\*\*

```{r}
set.seed(12345)
chaco_df_sample <- chaco_df %>% sample_n(1e4)

ggplot(
  chaco_df_sample,
  aes(
    P_anomaly_Chaco_2013,
    drought_severity
  )
) +
  geom_density_2d_filled(contour_var = "ndensity") +
  scale_fill_grey(start = 1, end = 0) +
  theme_light() +
  geom_smooth(method = "lm", se = F)

lm(P_anomaly_Chaco_2013 ~ drought_severity, data = chaco_df_sample) %>% 
  summary()


ggplot(
  chaco_df_sample,
  aes(P_anomaly_Chaco_2013, drought_severity)
) +
  geom_hex() +
  scale_fill_gradient(
    low = "grey90",
    high = "black"
  ) +
  theme_light() +
  geom_smooth(method = "lm", se = F) +
  labs(
    fill = "Counts per\nhexagon",
    x = "Precipitation anomaly [mm(?)]",
    y = "Difference in EVI, compared to\nreference period 2006-2012",
    title = "Chaco: 2013 drought",
    subtitle = "Correspondence of fewer precipitation and EVI decrease?",
    caption = "Blue line: linear model regression line"
  )
```

#### Examining EVI and precipitation anomaly for the year 2013

Use this code chunk to visualize the variables describing precipitation anomaly and the EVI in 2013 (question 2). As described in the assignment sheet, do this only for a random sample of 10000 observations.

```{r}
# not sure if I understood the task right - just visualizing EVI_2013 and P_anom here??

ggplot(
  chaco_df_sample,
  aes(
    P_anomaly_Chaco_2013,
    y2013
  )
) +
  geom_hex()
```

**Use this space to write your answer to question 03**

### Exercise III: Resilience of Chaco forests to droughts

#### Calculation of four resilience indicators by Gazol et al.

Use the code chunks below to calculate the resilience indices from Gazol et al. (2018).

```{r}
# 1. Resistance (Rt)
# resistance index (Rt) quantifies the difference  between EVI during the dry year and the preceding  3 years

```

```{r}
# 2. Recovery (Rc)


```

```{r}
# 3. Resilience (Rs)


```

```{r}
# 4. Relative Resilience (sRs)


```

```{r}
# Plot the maps side by side


```

-   Use this space here to answer question 4: "What commonalities do you see what are differences? Provide a few bullet points of your observations."\*

#### Calculation of time of recovery

Use the two chunks below to assess the recovery time of the forest areas that experienced a drought. This will require some thinking on the order of the processing, so that you do not overwrite important information. Once you have established a workflow for the non-spatial analysis, you can repeat the same processing technique for the spatial data.

```{r}
# Non-spatial


```

```{r}
# Spatial


```

```{r}
# Both plots combined


```

#### Export of the recovery map into a geospatial dataset

```{r}
writeRaster(THELAYERTOEXPORT, 'YOURFILENAMEHERE.tif', gdal=c('COMPRESS=DEFLATE'), overwrite=TRUE)
```

-   Use this space here to answer question 7\*
