---
title: "Ecosystem Dynamics and Global Change - Lab 5"
output:
  html_document:
    df_print: paged
---

## Lab 05 - Time Series Analysis

This .Rmd-File accompanies the description of the lab. It is meant to give you some guidance of the order of the processing as well as some smaller code examples that will help you going through the code. In some cases, you will have to come up with your own solution. As a first step - as usual - we load the libraries that we will need during the process. Make sure you use the up-to-date versions of the packages

```{r, silent=TRUE}
library(tidyverse)
library(terra)
library(sf)
library(tidyterra)
library(ggthemes)
```

### Exercise I: Getting to know the data

In moodle, you have received a raster stack and the assignment sheet describes the individual layers. Run the code chunk below to load the raster file, afterwards explore the data a bit to understand what the different layers will mean. The second line defines that the EVI of the year 2013 is being plotted.

```{r}
all_data <- rast('data_EDGC_Lab5.tif')

all_data <- all_data %>%
  mutate(across(starts_with("y"), ~ .x / 1e4))

ggplot() +
  geom_spatraster(
    data = all_data %>% select(starts_with("y"))
  ) +
  facet_wrap(~lyr) +
  scale_fill_gradientn(
    colours = c("orange", "white", "darkgreen"),
    limits = c(0, 1),
    name = "EVI",
    na.value = NA
  )

ggplot() +
  geom_spatraster(
    data = all_data, aes(fill = y2013)
  ) +
    scale_fill_gradientn(
    colours = c("orange", "white", "darkgreen"),
    limits = c(0, 1),
    name = "EVI",
    na.value = NA
  ) +
  labs(title = "2013")
```

Use the code chunk below to mask out the frontier areas by converting them into NA values. The instructions for what frontier areas are can be found in the assignment sheet. After that visualize the same band again as you did above.

```{r}
# quick check...
plot(all_data$onset_yr)
plot(all_data$onset_yr == 0)

# throw out anything but no-frontier-ever-pixels
all_data <- mask(
  all_data,
  all_data$onset_yr > 0,
  maskvalues = T
)

# check result
ggplot() +
  geom_spatraster(
    data = all_data, aes(fill = y2013)
  ) +
    scale_fill_gradientn(
    colours = c("orange", "white", "darkgreen"),
    limits = c(0, 1),
    name = "EVI",
    na.value = NA
  ) +
  labs(
    title = "2013",
    subtitle = "Any agricultural frontiers (1986-2019) are\nmasked out, unrelated to the year shown"
  )
```

### Exercise II: Preparing the data and exploring the drought impact

Apply the chunk below to create a new layer in the raster file that represents the average of the years 2006-2012. Execute the script and carefully examine what the individual commands do, including the parts that include the `tidyR`-syntax. Once you are done with this, use the empty code chunk below to create another new layer that represents the difference between the average of the period 2006-2012 and the drought year 2013. Plot the resulting map and examine the output.

#### Calculating the reference period

```{r}
year_evi_ras <- all_data %>% select(starts_with("y"))

time(year_evi_ras) <- names(year_evi_ras) %>%
  substr(2,5) %>% as.integer()

all_data$EVI_ref_2006_2012 <- year_evi_ras %>% 
  subset(
    time(year_evi_ras) %in% 2006:2012
  ) %>% 
  mean() %>% 
  rename(`reference period 2006-2012` = "mean")

# keep your environment clean:
#rm(year_evi_ras)
```

```{r}
all_data$drought_severity <- all_data$y2013 - all_data$EVI_ref_2006_2012

names(all_data$drought_severity) <- "EVI difference 2013 to reference period"

ggplot() +
  geom_spatraster(
    data = all_data,
    aes(fill = `drought_severity`)
  ) +
  scale_fill_gradient2(
    low = "red",
    mid = "white",
    high = "darkgreen",
    midpoint = 0,
    name = "EVI difference",
    na.value = NA
  ) +
  labs(title = "Comparison", subtitle = "2013 vs. reference period 2006-2012")
```

#### Examining EVI values

The code chunk below converts the raster file into a tibble (or data.frame). Execute the code below and carefully examine the newly created dataset. After that, continue with the instructions from the assignment sheet.

```{r}
# evi_pts <- as.points(all_data, values = TRUE, na.rm = TRUE, na.all = FALSE)
# evi_df = as.data.frame(evi_pts, geom = "XY")

# I think it's possible without transforming to points first:

chaco_df <- as.data.frame(all_data, xy = T, na.rm = T)

chaco_df_long <- chaco_df %>%
  pivot_longer(
    !c(x, y, onset_yr, dist_frontier, P_anomaly_Chaco_2013, EVI_ref_2006_2012, drought_severity),
    names_to = "Year",
    values_to = "EVI"
  ) %>% 
  mutate(Year = Year %>% substr(2,5) %>% as.integer())
```

**Question I:**

Provide a suitable visualization for the time series of EVI values. Think also about some summary statistics. Describe in a few sentences your graph, and discuss the suitability of the visualization for the data (but also: what problems do you see by manipulating the data in this way?).

```{r}
ggplot(
  chaco_df_long,
  aes(
    Year,
    EVI,
    group = Year
  )
) +
  geom_violin(fill = "grey", col = "grey") +
  geom_boxplot(width = .2, outliers = F) +
  theme_light() +
  stat_summary(aes(group = 1), colour="deepskyblue2", geom="crossbar") +
  labs(caption = "Blue crossbar represents the mean value") +
  scale_y_continuous(breaks = seq(0, 1, .2), minor_breaks = seq(0, 1, .05))


# Some statistics:

chaco_statistics <- inner_join(
  chaco_df_long %>% 
    group_by(Year) %>% 
    summarise(mean = mean(EVI), .groups = "drop"),
  chaco_df_long %>% 
    group_by(Year) %>% 
    summarise(
      quantile(
        EVI,
        probs = c(0, .05, .1, seq(.25, .75, .25), .9, .95, 1)
      ) %>% 
      as_tibble_row(.name_repair = \(x) paste0('q', parse_number(x)))
    ),
  by = "Year"
)

library(ggrepel)
ggplot(
  chaco_statistics %>% 
    pivot_longer(!Year) %>% 
    filter(!name %in% c("q0", "q100")),
  aes(Year, value, groups = name)
) +
  geom_line() +
  geom_point() +
  geom_label_repel(
    data = filter(
      chaco_statistics %>%
        pivot_longer(!Year) %>%
        filter(!name %in% c("q0", "q100")),
      Year == first(Year)),
    aes(label = name),
    direction = "y",
    segment.colour = "darkgrey"
  ) +
  theme_light()
```

The general problem of visualizing 4d data in a 3d or 2d way is that one of the dimensions has to fall short. This is one of the general problems of multispatiomultitemporal data... In this example, I decided to ignore the x and y, resp. the spatial location, by summarizing it. First plot:

-   The blue crossbars show the mean value over the years.

-   The boxplots show the median and quantiles.

-   In the background, the grey violin (density) plots give a sense of the value distribution.

Second plot: Visualization of the statistics, by simply plotting the mean and some percentiles across years.

This quickly gives a general overview, but completely ignores possible spatial disparities, i.e. spatial patterns.

**Question 2:**

Next, we want to see whether the areas (i.e., pixels) of drought severity and the precipitation anomaly correspond to each other. The basis for this analysis will again be the tibble you created in the previous step – yet, for visualization purposes, we want you to make this comparison based on a random sample of 10,000 points (i.e., pixels). Choose an appropriate visualization for this comparison – be creative here: add a trend line or a local regression. Combine the plot with the previous plot (i.e., the EVI time series)

Create a panel plot consisting of the comparison of ‘drought severity’ with the precipitation anomaly. Critically examining all the maps and plots you have created so far and discuss with your fellow classmates: is the drought of 2013 reflected in the EVI data? What can be problematic in using EVI for such an assessment? Could you think of alternative aggregations compared to the 90th percentile of annual EVI values that is being used here? Provide 2-3 sentences on your examinations; answer them inside the provided space in the .Rmd-File.\*\*

```{r}
set.seed(12345)
chaco_df_sample <- chaco_df %>% sample_n(1e4)

ggplot(
  chaco_df_sample,
  aes(
    P_anomaly_Chaco_2013,
    drought_severity
  )
) +
  geom_density_2d_filled(contour_var = "ndensity") +
  scale_fill_grey(start = 1, end = 0) +
  theme_light() +
  geom_smooth(method = "lm", se = F)

lm(P_anomaly_Chaco_2013 ~ drought_severity, data = chaco_df_sample) %>% 
  summary()


ggplot(
  chaco_df_sample,
  aes(P_anomaly_Chaco_2013, drought_severity)
) +
  geom_hex() +
  scale_fill_gradient(
    low = "grey90",
    high = "black"
  ) +
  theme_light() +
  geom_smooth(method = "lm", se = F) +
  labs(
    fill = "Counts per\nhexagon",
    x = "Precipitation anomaly [mm(?)]",
    y = "Difference in EVI, compared to\nreference period 2006-2012",
    title = "Chaco: 2013 drought",
    subtitle = "Correspondence of fewer precipitation and EVI decrease?",
    caption = "Blue line: linear model regression line"
  )
```

#### Examining EVI and precipitation anomaly for the year 2013

Use this code chunk to visualize the variables describing precipitation anomaly and the EVI in 2013 (question 2). As described in the assignment sheet, do this only for a random sample of 10000 observations.

```{r}
# not sure if I understood the task right - just visualizing EVI_2013 and P_anom here??

ggplot(
  chaco_df_sample,
  aes(
    P_anomaly_Chaco_2013,
    y2013
  )
) +
  geom_hex() +
  scale_fill_gradient(
    low = "grey90",
    high = "black"
  ) +
  theme_light() 
```

**Use this space to write your answer to question 03**

### Exercise III: Resilience of Chaco forests to droughts

#### Calculation of four resilience indicators by Gazol et al.

Use the code chunks below to calculate the resilience indices from Gazol et al. (2018).

```{r}
# 1. Resistance (Rt)
# difference  between EVI during the dry year and the preceding 3 years
# difference given in relative change/ratio, not absolut difference (Gazol et al., 2018)

get_Rt_ras <- function(years_ras, pointer_year){
  years_ras[[time(years_ras) == pointer_year]] /
    mean(years_ras[[
      time(years_ras) %in% (pointer_year-3):(pointer_year-1)
    ]]
  )
}

resilienceInd_Rt <- get_Rt_ras(year_evi_ras, 2013)

# Dividing by 0 could cause problems... However, there is just one value causing problems; I will just replace that with an NA. If it would have been more values, using the Normalized Difference insteas of the ratio would have been a nice solution.
global((resilienceInd_Rt %in% c(-Inf, Inf)), fun = "sum", na.rm = T)
resilienceInd_Rt <- resilienceInd_Rt %>%
  mask(resilienceInd_Rt, maskvalues = c(Inf, -Inf))

# quick and dirty check value distribution - majority of the values should be between 0 and something around 1:
freq(resilienceInd_Rt) %>% ggplot(
  aes(value, count)
) +
  geom_bar(stat = "identity") +
  labs(title = "Quick histogram check, to make sure it overall worked...")

# For the sake of simplicity, I will configure the plot in a way that simply incorporates all values, but matches the color ramp to the small, meaningful values:
plot_Rt <- ggplot() +
  geom_spatraster(
    data = resilienceInd_Rt
  ) +
  scale_fill_gradient2(
    low      = "darkred",  
    mid      = "white",    
    high     = "blue",    
    midpoint = 1,
    limits   = c(0, 1.5),
    # Inline-OOB-Funktion: clippt alles < –1 auf –1 und alles > 0.5 auf 0.5
    oob      = function(x, range) pmax(pmin(x, range[2]), range[1]),
    na.value = NA,
    breaks   = c(0, 1, 1.5),
    labels   = c("≤ 0", "1", "≥ 1.5"),
    name = "Rt"
  ) +
  labs(
    title = "Resistance (Rt)",
    subtitle = "mean of 2010-2012 in relation to 2013",
    caption = "Values are trimmed to focus\non plausible values"
  )

plot_Rt
```

```{r}
# 2. Recovery (Rc)

get_Rc_ras <- function(years_ras, pointer_year){
  mean(years_ras[[time(years_ras) %in% (pointer_year+1):(pointer_year+3)]])/
    years_ras[[time(years_ras) == pointer_year]]
}

resilienceInd_Rc <- get_Rc_ras(year_evi_ras, 2013)

# quick and dirty check value distribution - majority of the values should be between 0 and something around 1:
freq(resilienceInd_Rc) %>% View()
hist(resilienceInd_Rc)

plot_Rc <- ggplot() +
  geom_spatraster(
    data = resilienceInd_Rc
  ) +
  scale_fill_gradient2(
    low      = "darkred",
    mid      = "white",    
    high     = "blue",    
    midpoint = 1,
    limits   = c(0, 2),
    # Inline-OOB-Funktion: clippt alles < –1 auf –1 und alles > 0.5 auf 0.5
    oob      = function(x, range) pmax(pmin(x, range[2]), range[1]),
    na.value = NA,
    breaks   = c(0, 1, 2),
    labels   = c("≤ 0", "1", "≥ 2"),
    name = "Rc"
  ) +
  labs(
    title = "Recovery (Rc)",
    subtitle = "mean of 2014-2016 in relation to 2013",
    caption = "Values are trimmed to focus\non plausible values"
  )

plot_Rc
```

```{r}
# 3. Resilience (Rs)
# here, the difference is needed again

get_Rs_ras <- function(years_ras, pointer_year){
  mean(years_ras[[time(years_ras) %in% (pointer_year+1):(pointer_year+3)]])-
    mean(years_ras[[time(years_ras) %in% (pointer_year-3):(pointer_year-1)]])
}

resilienceInd_Rs <- get_Rs_ras(year_evi_ras, 2013)

plot_Rs <- ggplot() +
  geom_spatraster(
    data = resilienceInd_Rs
  ) +
  scale_fill_gradient2(
    low      = "darkred",
    mid      = "white",    
    high     = "blue",    
    midpoint = 0,
    limits   = c(-.25, .25),
    # Inline-OOB-Funktion: clippt alles < –1 auf –1 und alles > 0.5 auf 0.5
    oob      = function(x, range) pmax(pmin(x, range[2]), range[1]),
    na.value = NA,
    breaks   = c(-.25, -0, .25),
    labels   = c("≤ - 0.25", "0", "≥ 0.25"),
    name = "ΔEVI"
  ) +
  labs(
    title = "Resilience (Rs)",
    subtitle = "difference betw. 2010-2012 and 2014-2016",
    caption = "Values are trimmed to focus\non plausible values"
  )

plot_Rs
```

```{r}
# 4. Relative Resilience (sRs)
# resilience weighted by the growth reduction: difference between Rs and Rt (Gazol et al., 2018)

# My original understanding was to calculate Rs - Rt, but I think this makes more sense:
resilienceInd_rRs <- resilienceInd_Rs * (resilienceInd_Rt*-1)

freq(resilienceInd_rRs)

plot_rRs <- ggplot() +
  geom_spatraster(
    data = resilienceInd_rRs
  ) +
  scale_fill_gradient2(
    low      = "darkred",
    mid      = "white",    
    high     = "blue",    
    midpoint = 0,
    limits   = c(-.2, .2),
    # Inline-OOB-Funktion: clippt alles < –1 auf –1 und alles > 0.5 auf 0.5
    oob      = function(x, range) pmax(pmin(x, range[2]), range[1]),
    na.value = NA,
    breaks   = c(-.2, 0, .2),
    labels   = c("≤ -0.2", "0", "≥ 0.2"),
    name = "weighted index\n(dimensionless)"
  ) +
  labs(
    title = "Relative Resilience (rRs)",
    subtitle = "Resilience (Rs) weighted by growth reduction (Rt)",
    caption = "Values are trimmed to focus\non plausible values"
  )

plot_rRs
```

```{r}
# Plot the maps side by side

library(ggpubr)
ggarrange(
  plot_Rt + labs(caption = NULL, subtitle = NULL) + theme(legend.position="bottom"),
  plot_Rc + labs(caption = NULL, subtitle = NULL) + theme(legend.position="bottom"),
  plot_Rs + labs(caption = NULL, subtitle = NULL) + theme(legend.position="bottom"),
  plot_rRs + labs(caption = NULL, subtitle = NULL) + theme(legend.position="bottom"),
  nrow = 1
)

ggsave("combined_RIs.pdf", dpi = 300, width = 21*1.5, height = 14, units = "cm")
```

-   Use this space here to answer question 4: "What commonalities do you see what are differences? Provide a few bullet points of your observations."\*

#### Calculation of time of recovery

Use the two chunks below to assess the recovery time of the forest areas that experienced a drought. This will require some thinking on the order of the processing, so that you do not overwrite important information. Once you have established a workflow for the non-spatial analysis, you can repeat the same processing technique for the spatial data.

```{r}
# Non-spatial

drought_year <- 2013

# reference
recovery_reference <- chaco_df_long %>% 
  filter(Year %in% (drought_year-3):(drought_year-1)) %>% 
  group_by(x, y) %>% 
  summarise(EVI95 = mean(EVI), .groups = "drop") %>% 
  mutate(EVI95 = EVI95 * .95)

recovery_result <- chaco_df_long %>% 
  filter(Year > drought_year) %>% # I will not include 2013 itself here, because trees might show a (EVI-positive) compensation reaction, followed by a decline in the following years
  left_join(recovery_reference, by = c("x", "y")) %>%
  filter(EVI >= EVI95) %>% 
  group_by(x, y) %>% 
  summarise(recovery_year = min(Year), .groups = "drop") %>% 
  mutate(recovery_time = recovery_year - drought_year)

recovery_result_hist <- table(recovery_result$recovery_time) %>% t() %>% as.data.frame() %>% rename(x = Var2, count = Freq) %>% select(-Var1)

ggplot(
  recovery_result_hist,
  aes(x, count)
) +
  geom_bar(stat = "identity") +
  theme_light() +
  labs(x = "Years recovery", time, y = "Count of pixels")
```

```{r}
# Spatial

# I see 3 different ways:
# 1) Just creating a raster out of the result df from the before task; the x and y is still there. However, we loose information on the NA pixels then; they could be outside the AOI, or not recovered. This is a big disadvantage.
# 2) Usually, creating a function out of the code non-spatial code chunk and then apply it over all pixels. However, in the way I processed the data, this might not work, or only with significant workarounds. So this is a No, too.
# 3) Simply working with terra functions. Let's go.

# check if year-layers are in ascending order:
sum(!year_evi_ras %>% time() == 
      min(time(year_evi_ras)):
      max(time(year_evi_ras))) == 0

recovery_reference_ras <- mean(year_evi_ras[[time(year_evi_ras) %in% (drought_year-3):(drought_year-1)]]) * .95

# Again, I will not include 2013 itself here, because trees might show a (EVI-positive) compensation reaction, followed by a decline in the following years
recovery_result_years_ras <- year_evi_ras[[time(year_evi_ras) > drought_year]] >= recovery_reference_ras

yrs <- time(recovery_result_years_ras)

recovery_result_ras <- recovery_result_years_ras
for (i in seq_along(time(recovery_result_years_ras))) {
  recovery_result_ras[[i]] <- ifel(recovery_result_years_ras[[i]], time(recovery_result_years_ras)[i], 9999)
}

recovery_result_ras <- min(recovery_result_ras, na.rm = TRUE)
names(recovery_result_ras) <- "recovery_year"

recovery_result_ras_plot <- as.factor(recovery_result_ras)

# Dann die Levels setzen
levels(recovery_result_ras_plot) <- data.frame(
  value = c(yrs, 9999),  # NA wird hier nicht explizit als Level gesetzt
  label = c(as.character(yrs), "not recovered")
)

ggplot() +
  geom_spatraster(
    data = recovery_result_ras_plot
  ) +
  scale_fill_discrete(na.translate = FALSE)
```

```{r}
# Both plots combined



# margin means: library(ggExtra): https://r-graph-gallery.com/277-marginal-histogram-for-ggplot2.html
```

#### Export of the recovery map into a geospatial dataset

```{r}
writeRaster(THELAYERTOEXPORT, 'YOURFILENAMEHERE.tif', gdal=c('COMPRESS=DEFLATE'), overwrite=TRUE)
```

-   Use this space here to answer question 7\*
